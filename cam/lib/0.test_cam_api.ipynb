{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import sys\n",
    "sys.path.append('./cam2')\n",
    "\n",
    "import click\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.hub\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from grad_cam import (\n",
    "    BackPropagation,\n",
    "    Deconvnet,\n",
    "    GradCAM,\n",
    "    GuidedBackPropagation,\n",
    "    occlusion_sensitivity,\n",
    ")\n",
    "\n",
    "from main import get_device, get_classtable\n",
    "\n",
    "# import resnet34 for dr classification\n",
    "sys.path.append('/home/zhangwd/code/work/xrayproduct/drCls/train/')\n",
    "from resnet import *\n",
    "from dr_model import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DRModel('rsn34', 1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_file = '/home/zhangwd/code/work/xrayproduct/drCls/train/dr_cls_yyy/ct_pos_recognition_0010_best.pth'\n",
    "model.load_state_dict(torch.load(weights_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DRModel(\n",
       "    (base): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.DataParallel(model).cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [\"relu\", \"layer1\", \"layer2\", \"layer3\", \"layer4\"]\n",
    "target_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images:\n",
      "\t#0: /home/zhangwd/code/work/xrayproduct/chestx-ray8/lib/chexnet/test1/00009285_000.png\n",
      "255.0\n",
      "torch.Size([1, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image_path):\n",
    "    raw_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    raw_image = cv2.resize(raw_image, (1024,1024))\n",
    "    img1 = raw_image.copy()\n",
    "    img1 = np.array(img1, dtype=np.float)\n",
    "    img1 = img1\n",
    "    print(img1.max())\n",
    "    input_img = torch.from_numpy(img1)\n",
    "    input_img = torch.unsqueeze(input_img, 0)\n",
    "    return input_img, raw_image\n",
    "\n",
    "\n",
    "# image_paths = ['./cam2/samples/cat_dog.png']\n",
    "image_paths = ['/home/zhangwd/code/work/xrayproduct/chestx-ray8/lib/chexnet/test1/00009285_000.png']\n",
    "images = []\n",
    "raw_images = []\n",
    "print(\"Images:\")\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    print(\"\\t#{}: {}\".format(i, image_path))\n",
    "    image, raw_image = preprocess(image_path)\n",
    "    images.append(image)\n",
    "    raw_images.append(raw_image)\n",
    "images = torch.stack(images)\n",
    "images = images.float().cuda()\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = get_classtable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcam = GradCAM(model=model)\n",
    "probs, ids = gcam.forward(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 0\n",
    "ids_ = torch.LongTensor([[target_class]] * len(images)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]], device='cuda:0', grad_fn=<SortBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcam.backward(ids=ids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GeForce GTX 1080 Ti\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_device(cuda):\n",
    "    cuda = cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    if cuda:\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "    else:\n",
    "        print(\"Device: CPU\")\n",
    "    return device\n",
    "device = get_device(True)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gradcam(filename, gcam, raw_image, paper_cmap=True):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    cmap = cm.jet_r(gcam)[..., :3]*255\n",
    "    img_rgb = cv2.cvtColor(raw_image, cv2.COLOR_GRAY2RGB)\n",
    "    if paper_cmap:\n",
    "        alpha = gcam[..., None]\n",
    "        gcam = alpha * cmap + (1 - alpha) * img_rgb\n",
    "    else:\n",
    "        gcam = (cmap.astype(np.float) + img_rgb.astype(np.float)) / 2\n",
    "    cv2.imwrite(filename, np.uint8(gcam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Grad-CAM @module.base.2\n",
      "regions:\n",
      "torch.Size([1, 1, 1024, 1024])\n",
      "Generating Grad-CAM @module.base.4\n",
      "regions:\n",
      "torch.Size([1, 1, 1024, 1024])\n",
      "Generating Grad-CAM @module.base.5\n",
      "regions:\n",
      "torch.Size([1, 1, 1024, 1024])\n",
      "Generating Grad-CAM @module.base.6\n",
      "regions:\n",
      "torch.Size([1, 1, 1024, 1024])\n",
      "Generating Grad-CAM @module.base.7\n",
      "regions:\n",
      "torch.Size([1, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    target_layers = [\"module.base.2\", \"module.base.4\", \"module.base.5\", \"module.base.6\", \"module.base.7\"]\n",
    "    output_dir = './xxx' \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for target_layer in target_layers:\n",
    "        print(\"Generating Grad-CAM @{}\".format(target_layer))\n",
    "\n",
    "        # Grad-CAM\n",
    "        regions = gcam.generate(target_layer=target_layer)\n",
    "        print('regions:')\n",
    "        print(regions.shape)\n",
    "\n",
    "        for j in range(len(images)):\n",
    "#             print(\n",
    "#                 \"\\t#{}: {} ({:.5f})\".format(\n",
    "#                     j, classes[target_class], float(probs[ids == target_class])\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "            save_gradcam(\n",
    "                filename=osp.join(\n",
    "                    output_dir,\n",
    "                    \"{}-{}-gradcam-{}-{}.png\".format(\n",
    "                        j, \"resnet152\", target_layer, 'xxx'\n",
    "                    ),\n",
    "                ),\n",
    "                gcam=regions[j, 0],\n",
    "                raw_image=raw_images[j],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsn_model = torchvision.models.resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in rsn_model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rsn_model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5743a4ef28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAP0UlEQVR4nO3df4hd9ZnH8feT+KNWZd2sNZ0mcWOXFGqFtRK04FJcZLs1FNL+oehC1TZ0+kdCt+CC0S5U1n+yS7W4dJEdqdQs1SjbiqFk11pZkYVqjZL6c21TTXWaIdFdsWG7VWd89o9zpr3OvTP3ZjI394m+XzDce8+ce87DId/PfL/f8yORmUhSp2WjLkBSPQaDpC4Gg6QuBoOkLgaDpC4Gg6QuQwuGiPh0RDwfEXsjYuuw9iNp6cUwrmOIiOXAz4C/ACaBx4ArMvPZJd+ZpCU3rB7D+cDezHwhM98EdgAbh7QvSUvsuCFtdxXwcsfnSeCC+VZ+f0SeNqRCJDWm4NXM/MAg6w4rGKLHsneMWSJiHBgH+ANg85AKkdT4W/jloOsOKxgmgTUdn1cD+ztXyMwJYAJgdUQOqxBJh29Y7fExYF1EnAX8Crgc+Kv5Vl4GnDSkQiQdvqEEQ2ZOR8QW4H5gOXB7Zj4z3/oBHD+MQiQtytB68Jm5C9g1yLoxzEIkHbYS7dEeg1RLmWAoUYgkoEh7tMcg1VImGDwrIdVRJhjsMUh1lAmGEoVIAoq0R3sMUi1lgqFEIZKAIu3RS6KlWkoEg0MJqZYywVCiEElAkfZoj0GqpUQwQKFCJNVoj/YYpFpKBMMy4KTlo65CepebGXzVEsEQAceXqER6FzsWg+G4EpVI72JvDL5qieZoj0GqpURzDOA45xikMkoEAwFRoxJJFAoGThx1EZJm1QmGGpVIokpzNBikUmo0x6D5b2kklVAjGKBSJdJ7Xo3m6FBCKqVGc1yGZyWkQmoEA1SqRHrPq9EcHUpIpdRojp6VkEqpEww1KpFEleboJdFSKXWCoUYlkqjSHA0GqZQjao4RsQ84RPPQqOnMXB8RK4C7gbXAPuCyzHxt4Q0daSWSltJSNMc/z8xXOz5vBR7MzG0RsbX9fG3frXhWQipjGH+nNwIXte/vAB6iXzDYY5BKOdLmmMAPIyKBf87MCWBlZk4BZOZURJzR64sRMQ6MA5x5Cp6VkAo50mC4MDP3t43/gYj4r0G/2IbIBMD6MyLtMUh1HFFzzMz97evBiLgXOB84EBFjbW9hDDjYd0MOJaRSFt0cI+JkYFlmHmrffwr4O2AncBWwrX29r//GjqQSSUvtSJrjSuDeiJjdzp2Z+e8R8RhwT0RsAl4CLh1oa56VkMpYdDBk5gvAn/ZY/t/AxYe1MXsMUik1mqMPapFKqREMUKkS6T2vRnN0KCGVUqM5+qAWqZQ6wVCjEklUaY4BvG/URUiaVScYHEpIZdQJhhqVSKJKczQYpFLqNEeHElIZNYLBHoNUSo3m6OPjpVLqBEONSiRRpTkaDFIpNZqjwSCVUqc5elZCKqNGMNhjkEqp0Rx9UItUSo1ggEqVSO95NZqjQwmplBrN0WCQSqnRHL3tWiqlRjBApUqk97wazdGzElIpNYLBOQaplDLNMctUIqlEc8yAaScfpTJKBAMBMzUqkUSRYHh7WfDm+0qUIr2LvTXwmiVaYwLTyx1LSMN1jAUDBDNVSpFUozUmwYyXPkpllAgGwGCQCukbDBFxO/AZ4GBmntMuWwHcDawF9gGXZeZrERHALcAG4DfA1Zn5RL99JMG0wSCVMUiP4TvAt4DtHcu2Ag9m5raI2Np+vha4BFjX/lwA3Nq+LigJ3vSaaKmMvsGQmQ9HxNo5izcCF7Xv7wAeogmGjcD2zEzgkYg4LSLGMnNqwX04xyCVstg5hpWzjT0zpyLijHb5KuDljvUm22V9gsE5BqmSpZ58jB7LsueKEePAOMDYmcc5xyAVsthgODA7RIiIMeBgu3wSWNOx3mpgf68NZOYEMAFw9vqT0usYpDoW2xp3AlcB29rX+zqWb4mIHTSTjq/3m18AhxJSNYOcrryLZqLx9IiYBL5OEwj3RMQm4CXg0nb1XTSnKvfSnK78wiBFJMt4gxMOu3hJwzHIWYkr5vnVxT3WTWDz4RbR9BgcSkhVFGmNnq6UKikRDF7HINVSIhjAyUepkhLB4L0SUi1lgsF7JaQ6ygSDQwmpjiLBgEMJqZASweCj3aRaSrRGhxJSLWWC4U0viZbKKBMMzjFIdZQJBucYpDrKtEbnGKQ6SgSDk49SLUWCwesYpEqKBMMyL4mWCikSDM4xSJWUCAY8XSmVUiIYPF0p1VKiNTqUkGopEQw+81GqpUQwvE34+HipkBLB4G3XUi0lWqNXPkq1lAgGcPJRqqREMHjbtVRLmWBwjkGqo0Rr9AlOUi1lgsE5BqmOIsHgbddSJSWCwesYpFpKtEaHElItZYLBS6KlOsoEg0MJqY6+rTEibgc+AxzMzHPaZTcAXwJeaVe7PjN3tb+7DtgEzABfycz7BynEoYRUxyB/pr8DfAvYPmf5NzPzG50LIuJs4HLgY8CHgB9FxEcyc2ahHTjHINXSNxgy8+GIWDvg9jYCOzLzDeDFiNgLnA/8eMF9YI9BquRIBvZbIuJKYDdwTWa+BqwCHulYZ7Jd1iUixoFxgBPOXOl1DFIhiw2GW4Ebaf7Y3wjcBHwRiB7rZq8NZOYEMAFw0vqPpo+Pl+pYVDBk5oHZ9xFxG/CD9uMksKZj1dXA/v5bdI5BqmRRwRARY5k51X78HPB0+34ncGdE3Ewz+bgO+Em/7XnbtVTLIKcr7wIuAk6PiEng68BFEXEuzTBhH/BlgMx8JiLuAZ4FpoHN/c5IwOzko9cxSFVEZs8pgKPqxPXn5Njufx11GdK72i/jo49n5vpB1i3xZ9rrGKRaygTDG56VkMooEwwzM/YYpCpKBAMJM9MGg1RFiWDIDINBKqRIMMC0wSCVUSIYyGBmukYpkooEQ+Yy3vqtT3CSqigRDM1joh1KSFUUCYYAhxJSGTVaYwLTve7YljQKhYJh1EVImlUnGH476iIkzaoTDPYYpDIMBkldDAZJXWoEAxgMUiE1gsEeg1RKjWB4G89KSIXUCAZ7DFIpNYIBDAapkBrBYI9BKsVgkNTFYJDUpUYweFZCKqVGMIA9BqmQGsHgUEIqxWCQ1MVgkNSlTjA4+SiVUScY7DFIZRgMkroYDJK69A2GiFgDbAc+SHMp0kRm3hIRK4C7gbXAPuCyzHwtIgK4BdgA/Aa4OjOfWHAnBoNUyiA9hmngmsx8IiJOBR6PiAeAq4EHM3NbRGwFtgLXApcA69qfC4Bb29f+e5FUQt9gyMwpYKp9fygingNWARuBi9rV7gAeogmGjcD2zEzgkYg4LSLG2u305iXRUimHNccQEWuBjwOPAitnG3tmTkXEGe1qq4CXO7422S6bPxgcSkilDBwMEXEK8D3gq5n562YqofeqPZZlj+2NA+MAvP9Mg0EqZKBgiIjjaULhu5n5/XbxgdkhQkSMAQfb5ZPAmo6vrwb2z91mZk4AEwCxYn0aDFIdg5yVCODbwHOZeXPHr3YCVwHb2tf7OpZviYgdNJOOry84vwAOJaRiBukxXAh8HngqIva0y66nCYR7ImIT8BJwafu7XTSnKvfSnK78Qt89GAxSKYOclfhPes8bAFzcY/0ENh9WFZ6VkErxykdJXWoEAxgMUiE1gsEeg1SKwSCpi8EgqUudYPCshFRGnWCwxyCVYTBI6mIwSOpiMEjqUicYnHyUyqgTDPYYpDIMBkldDAZJXWoEAxgMUiHLRl2ApHoMBkld6gwluh8kLWlEigSDs49SJYWC4a1RFyGpVSgY7DFIVRQKBnsMUhVFguFt4P9GXYSkVpFgsMcgVVIkGMA5BqmOIsFgj0GqpFAw2GOQqigUDPYYpCqKBINnJaRKigSDQwmpkkLB4FBCqqJQMNhjkKooFAz2GKQqCgWDk49SFX2DISLWANuBD9KcPpjIzFsi4gbgS8Ar7arXZ+au9jvXAZuAGeArmXn/wnuxxyBVMkiPYRq4JjOfiIhTgccj4oH2d9/MzG90rhwRZwOXAx8DPgT8KCI+kpkz8+/COQapkr7BkJlTwFT7/lBEPAesWuArG4EdmfkG8GJE7AXOB368wF6wxyDVcVhzDBGxFvg48ChwIbAlIq4EdtP0Kl6jCY1HOr42SY8giYhxYLz5tAJ7DFIdAwdDRJwCfA/4amb+OiJuBW6k+XN/I3AT8EUgeny960mvmTkBTDTbPjPtMUh1DBQMEXE8TSh8NzO/D5CZBzp+fxvwg/bjJLCm4+urgf0L78FLoqVKBjkrEcC3gecy8+aO5WPt/APA54Cn2/c7gTsj4maaycd1wE8W3ouTj1Ilg/QYLgQ+DzwVEXvaZdcDV0TEuTSteh/wZYDMfCYi7gGepWntmxc+IwFOPkq1RObo/6OXiHgF+F/g1VHXMoDTOTbqhGOnVutcer1q/ePM/MAgXy4RDAARsTsz14+6jn6OlTrh2KnVOpfekdbq/10pqYvBIKlLpWCYGHUBAzpW6oRjp1brXHpHVGuZOQZJdVTqMUgqYuTBEBGfjojnI2JvRGwddT1zRcS+iHgqIvZExO522YqIeCAift6+/uEI6ro9Ig5GxNMdy3rWFY1/bI/xkxFxXoFab4iIX7XHdU9EbOj43XVtrc9HxF8exTrXRMR/RMRzEfFMRPx1u7zUcV2gzqU7ppk5sh9gOfAL4MPACcBPgbNHWVOPGvcBp89Z9g/A1vb9VuDvR1DXJ4HzgKf71QVsAP6N5j6WTwCPFqj1BuBveqx7dvvv4ETgrPbfx/KjVOcYcF77/lTgZ209pY7rAnUu2TEddY/hfGBvZr6QmW8CO2hu265uI3BH+/4O4LNHu4DMfBj4nzmL56trI7A9G48Ap0XE2NGpdN5a5/O72/Yz80Vg9rb9ocvMqcx8on1/CJh9xECp47pAnfM57GM66mBYBbzc8bnnLdojlsAPI+Lx9lZxgJXZ3ifSvp4xsureab66qh7nLW0X/PaO4ViJWuc8YqDscZ1TJyzRMR11MAx0i/aIXZiZ5wGXAJsj4pOjLmgRKh7nW4E/Ac6leRDQTe3ykdc69xEDC63aY9lRq7VHnUt2TEcdDIu4Rfvoysz97etB4F6aLtiB2S5j+3pwdBW+w3x1lTvOmXkgM2cy823gNn7ftR1prb0eMUDB4zrfoxCW6piOOhgeA9ZFxFkRcQLNsyJ3jrim34mIk9vnXBIRJwOform9fCdwVbvaVcB9o6mwy3x17QSubGfRPwG8nr+/ZX4k5ozF5962f3lEnBgRZzHQbftLVlPPRwxQ7LjOV+eSHtOjMYvaZ4Z1A82s6i+Ar426njm1fZhmNvenwDOz9QF/BDwI/Lx9XTGC2u6i6S6+RfMXYdN8ddF0Jf+pPcZPAesL1PovbS1Ptv9wxzrW/1pb6/PAJUexzj+j6WI/CexpfzZUO64L1Llkx9QrHyV1GfVQQlJBBoOkLgaDpC4Gg6QuBoOkLgaDpC4Gg6QuBoOkLv8PznqBbg+YRiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.arange(256*256)/256/256\n",
    "\n",
    "heatmap = np.resize(heatmap, [256,256])\n",
    "heatmap = cm.jet_r(heatmap)\n",
    "plt.figure()\n",
    "plt.imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py36] *",
   "language": "python",
   "name": "conda-env-.conda-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
